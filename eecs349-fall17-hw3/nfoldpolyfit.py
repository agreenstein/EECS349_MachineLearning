import sys
import csv
import numpy as np
import scipy
import matplotlib.pyplot as plt
import random

def nfoldpolyfit(X, Y, maxK, n, verbose):
#	NFOLDPOLYFIT Fit polynomial of the best degree to data.
#   NFOLDPOLYFIT(X,Y,maxDegree, nFold, verbose) finds and returns the coefficients 
#   of a polynomial P(X) of a degree between 1 and N that fits the data Y 
#   best in a least-squares sense, averaged over nFold trials of cross validation.
#
#   P is a vector (in numpy) of length N+1 containing the polynomial coefficients in
#   descending powers, P(1)*X^N + P(2)*X^(N-1) +...+ P(N)*X + P(N+1). use
#   numpy.polyval(P,Z) for some vector of input Z to see the output.
#
#   X and Y are vectors of datapoints specifying  input (X) and output (Y)
#   of the function to be learned. Class support for inputs X,Y: 
#   float, double, single
#
#   maxDegree is the highest degree polynomial to be tried. For example, if
#   maxDegree = 3, then polynomials of degree 0, 1, 2, 3 would be tried.
#
#   nFold sets the number of folds in nfold cross validation when finding
#   the best polynomial. Data is split into n parts and the polynomial is run n
#   times for each degree: testing on 1/n data points and training on the
#   rest.
#
#   verbose, if set to 1 shows mean squared error as a function of the 
#   degrees of the polynomial on one plot, and displays the fit of the best
#   polynomial to the data in a second plot.
#   
#
#   AUTHOR: Adam Greenstein (ajg362)
#
	# Split the examples into sets of training and test data for each fold
	# Determine the number of elements in each fold
	fold_size = len(X) / n
	# Randomly generate a list of the indices between 0 and the length of X (sample without replacement)
	rand_indices = random.sample(xrange(len(X)), len(X))
	XY_sets = []
	for fold_count in range(n):
		start = fold_size * fold_count
		end = fold_size * (fold_count + 1)
		if fold_count != n - 1:
			curr_indices = rand_indices[start:end]
		else:
			curr_indices = rand_indices[start:(len(rand_indices))]
		XY_sets.append(curr_indices)

	functions = [] # array to keep track of the functions generated by fitting the polynomials
	results = [] # array to keep track of the Mean Square Error results for the different polynomials of the different folds
	# go through the n groups of testing sets and fit a function to the data for values of k between 0 and maxK
	for curr_n in range(n):
		curr_functions = []
		curr_results = []
		X_train = []
		X_test = []
		Y_train = []
		Y_test = []
		# add the x/y values at the indices of the current test set to X_test/Y_test
		for idx in XY_sets[curr_n]:
			X_test.append(X[idx])
			Y_test.append(Y[idx])
		# add the x/y values at the other indices to X_train/Y_train
		for i in range(len(X)):
			if i not in XY_sets[curr_n]:
				X_train.append(X[i])
				Y_train.append(Y[i])
		# go through the possible polynomials and fit a function to the data
		for k in range(maxK + 1):
			P = np.polyfit(X_train, Y_train, k)
			curr_functions.append(P)
			# go through testing data and calculate sum of squared error
			sse = 0
			for i in range(len(X_test)):
				sse += (Y_test[i] - np.polyval(P, X_test[i]))**2
			curr_results.append(sse)
		functions.append(curr_functions)
		results.append(curr_results)


	# get the mean error for each k
	results = np.array(results)
	result_means = results.mean(0)
	best_k = np.where(result_means == result_means.min())
	# print "best k is: %d" %k
	best_result_of_best_k = results[:,best_k].min()
	best_idx = np.where(results == best_result_of_best_k)
	best_function = functions[best_idx[0][0]][best_idx[1][0]]
	three = np.polyval(best_function, 3)
	# print "Value when plugging in 3: %f" % three
	if verbose == 1:
		# create an array of k values for plotting the mean square error on the validation sets
		k_array = []
		for i in range(len(results)):
			k_array.append(np.arange(maxK + 1))
		k_array = np.array(k_array)
		plt.scatter(k_array, results, color = "blue", marker = "d")
		plt.plot(np.arange(maxK + 1), result_means, color = "red", marker="o")
		plt.legend(("Mean Squared Error","Sample SSE"), loc = 0, prop={'size': 8})
		plt.xlabel("k (degree of polynomial)")
		plt.ylabel("Sum of Squared Errors")
		plt.title("Error of Validation Sets for Each Polynomial Degree")
		plt.xticks(np.arange(maxK + 1))
		plt.draw()

		# plot the best function overlaying a scatterplot of the data
		plt.figure()
		plt.scatter(X,Y, color = "blue")
		s = np.linspace(X.min(),X.max(),10000)
		plt.scatter(s, np.polyval(best_function, s), color="red", s=2)
		plt.legend(("Input Data", "Polynomial Fit Line (k = %d)" % best_k), loc = 0, prop={'size': 8})
		plt.xlabel("X")
		plt.ylabel("Y")
		plt.title("%d-degree " % best_k + "Polynomial Best Fit Line for %d-fold Cross Validation" % n)
		plt.show()
	print "Coefficients of polynomial P(X) of degree %d" % best_k + " that best fits the data Y in a least-squares sense: %s" % str(best_function)
	return best_function


def main():
	# read in system arguments, first the csv file, max degree fit, number of folds, verbose
	rfile = sys.argv[1]
	maxK = int(sys.argv[2])
	nFolds = int(sys.argv[3])
	verbose = bool(int(sys.argv[4]))
	
	csvfile = open(rfile, 'rb')
	dat = csv.reader(csvfile, delimiter=',')
	X = []
	Y = []
	# put the x coordinates in the list X, the y coordinates in the list Y
	for i, row in enumerate(dat):
		if i > 0:
			X.append(float(row[0]))
			Y.append(float(row[1]))
	X = np.array(X)
	Y = np.array(Y)
	if nFolds < 2:
		print "Number of folds must be at least 2"
	else:
		nfoldpolyfit(X, Y, maxK, nFolds, verbose)

if __name__ == "__main__":
	main()
